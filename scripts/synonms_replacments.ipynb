{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n",
      "Current directory: /app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms for 'drive': push back, driving force, force, force back, motor, labour, cause, movement, ride, repulse, tug, ram, parkway, crusade, driving, effort, driveway, private road, push, campaign, beat back, thrust, aim, take, drive, get, labor, repel\n",
      "\n",
      "Similarity scores:\n",
      "drive: 1.0000\n",
      "driving: 0.6092\n",
      "get: 0.4795\n",
      "force: 0.4522\n",
      "take: 0.4364\n",
      "aim: 0.4215\n",
      "effort: 0.4090\n",
      "push: 0.3694\n",
      "campaign: 0.3586\n",
      "cause: 0.3125\n",
      "ride: 0.2931\n",
      "labor: 0.2671\n",
      "labour: 0.2384\n",
      "motor: 0.2042\n",
      "driveway: 0.1954\n",
      "ram: 0.1689\n",
      "parkway: 0.1641\n",
      "movement: 0.1388\n",
      "repel: 0.0568\n",
      "crusade: 0.0267\n",
      "tug: 0.0087\n",
      "thrust: -0.0008\n",
      "\n",
      "Least similar word: thrust (-0.0008)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '64'\n",
    "print(os.getcwd())\n",
    "os.chdir('/app')  # Change to your project directory\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "# Ensure the necessary NLTK data is downloaded\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Load a pre-trained Word2Vec model\n",
    "# Replace this with the path to your Word2Vec model (e.g., Google News model)\n",
    "model_path = \"embedding_files/datasets/word2vec_1billion/custom_word2vec.model\"\n",
    "try:\n",
    "    word2vec = Word2Vec.load(model_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Word2Vec model: {e}\")\n",
    "    exit()\n",
    "\n",
    "def get_synonyms(word):\n",
    "    \"\"\"Fetch synonyms of the given word using WordNet.\"\"\"\n",
    "    synonyms = set()\n",
    "    for synset in wn.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.add(lemma.name().replace('_', ' '))\n",
    "    return synonyms\n",
    "\n",
    "def calculate_similarity(word, synonyms, model):\n",
    "    \"\"\"Calculate similarity between the word and its synonyms using Word2Vec.\"\"\"\n",
    "    similarities = {}\n",
    "    for synonym in synonyms:\n",
    "        if synonym in model.wv.key_to_index and word in model.wv.key_to_index:\n",
    "            similarity = model.wv.similarity(word, synonym)\n",
    "            similarities[synonym] = similarity\n",
    "    return similarities\n",
    "\n",
    "# Input word\n",
    "word = \"drive\"\n",
    "\n",
    "# Get synonyms\n",
    "synonyms = get_synonyms(word)\n",
    "if not synonyms:\n",
    "    print(f\"No synonyms found for '{word}'.\")\n",
    "else:\n",
    "    print(f\"Synonyms for '{word}': {', '.join(synonyms)}\")\n",
    "\n",
    "    # Calculate similarity\n",
    "    similarities = calculate_similarity(word, synonyms, word2vec)\n",
    "    if not similarities:\n",
    "        print(f\"No similarities calculated (word or synonyms missing in Word2Vec vocabulary).\")\n",
    "    else:\n",
    "        print(\"\\nSimilarity scores:\")\n",
    "        for synonym, score in sorted(similarities.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"{synonym}: {score:.4f}\")\n",
    "        least_similar_word = min(similarities, key=similarities.get)\n",
    "        print(f\"\\nLeast similar word: {least_similar_word} ({similarities[least_similar_word]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n",
      "Current directory: /app\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir('/app')  # Change to your project directory\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "def process_json_files(folder_path):\n",
    "    # Loop through the files in the given directory\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file contains \"raws\" and ends with \".json\"\n",
    "        if \"raw_data\" in filename and filename.endswith(\"raw_data.json\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Open and read the JSON file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            # Keep only 'original' and 'sampled'\n",
    "            processed_data = {\n",
    "                \"original\": data.get(\"original\", []),\n",
    "                \"sampled\": data.get(\"sampled\", [])\n",
    "            }\n",
    "\n",
    "            # Write the processed data back into the JSON file\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                json.dump(processed_data, file, indent=4)\n",
    "\n",
    "# Example usage:\n",
    "folder_path = \"exp_main/data/original\"\n",
    "process_json_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms for 'car': motorcar, railcar, auto, cable car, machine, elevator car, car, automobile, railroad car, railway car, gondola\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ahmedkk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ahmedkk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Ensure the necessary NLTK data is downloaded\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def get_synonyms(word):\n",
    "    \"\"\"Fetch synonyms of the given word using WordNet.\"\"\"\n",
    "    synonyms = set()\n",
    "    for synset in wn.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.add(lemma.name().replace('_', ' '))\n",
    "    return synonyms\n",
    "\n",
    "word = \"car\"\n",
    "synonyms = get_synonyms(word)\n",
    "if not synonyms:\n",
    "    print(f\"No synonyms found for '{word}'.\")\n",
    "else:\n",
    "    print(f\"Synonyms for '{word}': {', '.join(synonyms)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
